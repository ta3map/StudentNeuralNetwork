{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detailed-marking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Default environment (dev)\" as SERVER\n",
      "learning...\n",
      "(23, 10) (23, 10)\n",
      "Epoch: 10; Error: 31.557531385752746;\n",
      "Epoch: 20; Error: 19.61460420859792;\n",
      "Epoch: 30; Error: 14.258013214939458;\n",
      "Epoch: 40; Error: 10.995244063536209;\n",
      "Epoch: 50; Error: 8.321067367263378;\n",
      "Epoch: 60; Error: 6.784247783588194;\n",
      "Epoch: 70; Error: 5.1662298667689175;\n",
      "Epoch: 80; Error: 4.310635658568226;\n",
      "Epoch: 90; Error: 4.00234155597642;\n",
      "Epoch: 100; Error: 3.799570453691637;\n",
      "The maximum number of train epochs is reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azat\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\Azat\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 27) (23, 17)\n",
      "Epoch: 10; Error: 126.30095873490811;\n",
      "Epoch: 20; Error: 93.62630121092755;\n",
      "Epoch: 30; Error: 60.348207319706916;\n",
      "Epoch: 40; Error: 38.13229769915888;\n",
      "Epoch: 50; Error: 28.87980335355317;\n",
      "Epoch: 60; Error: 25.16077325594162;\n",
      "Epoch: 70; Error: 20.97728230722405;\n",
      "Epoch: 80; Error: 17.884042005204165;\n",
      "Epoch: 90; Error: 16.381371486171027;\n",
      "Epoch: 100; Error: 15.421569878038603;\n",
      "The maximum number of train epochs is reached\n",
      "(23, 68) (23, 41)\n",
      "Epoch: 10; Error: 12.66699829500884;\n",
      "Epoch: 20; Error: 4.948011326915909;\n",
      "Epoch: 30; Error: 3.2184246141732187;\n",
      "Epoch: 40; Error: 2.118998942261774;\n",
      "Epoch: 50; Error: 1.3824732499779926;\n",
      "Epoch: 60; Error: 0.6754989903230663;\n",
      "Epoch: 70; Error: 0.5478741202644137;\n",
      "Epoch: 80; Error: 0.5061268093480196;\n",
      "Epoch: 90; Error: 0.5015966934400151;\n",
      "Epoch: 100; Error: 0.5003174406212751;\n",
      "The maximum number of train epochs is reached\n",
      "[2018 2019 2020 2021]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e188b696e7a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[0mwebbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://OHI7U7ZW5FYT3CYA.anvil.app/EDVDCBWVPGRCDNKKX6IBF22R\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[0manvil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RMSJ4GHU4YIGH3T5VHOWSHL2-OHI7U7ZW5FYT3CYA'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m \u001b[0manvil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_forever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\anvil\\server.py\u001b[0m in \u001b[0;36mwait_forever\u001b[1;34m()\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import neurolab as nl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import pickle\n",
    "import anvil.server\n",
    "import os\n",
    "import webbrowser\n",
    "import time\n",
    "\n",
    "print('wait for initialization...')\n",
    "# function for getting data from the year\n",
    "def getYear(df, year):\n",
    "  spike_cols = [col for col in df.columns if str(year) in col]\n",
    "  data_out = df[spike_cols].to_numpy()[:].astype(int)\n",
    "  columns = df[spike_cols].columns\n",
    "  return data_out, columns\n",
    "\n",
    "def regressGrades(first_year, second_year):\n",
    "  noise = np.random.rand(1)*0.1\n",
    "  ouput_size = np.size(second_year, 1)\n",
    "  input_size = np.size(first_year, 1)\n",
    "  R2 = [];\n",
    "  for j in range(ouput_size): # output index \n",
    "    R1 = [];  \n",
    "    for i in range(input_size):  # input index\n",
    "      r = np.corrcoef(first_year[:, i], second_year[:, j]+noise)      \n",
    "      R1.append(r[0, 1])\n",
    "    R2.append(R1);\n",
    "  return np.array(R2)\n",
    "\n",
    "def predictGrades(grades_in, R2):\n",
    "  from numpy.linalg import norm\n",
    "  ouput_size = np.size(R2, 0)\n",
    "  G = [];\n",
    "  for j in range(ouput_size):\n",
    "    R = R2[j]\n",
    "    R[R<0] = 0# avoid negative correlation\n",
    "    grade_out = norm(R*grades_in)/norm(R)\n",
    "    G.append(grade_out)\n",
    "  return np.array(G)\n",
    "\n",
    "def miniNet(inp, tar):\n",
    "  full_data = np.hstack((inp, tar))\n",
    "  minmax = [[np.min(full_data), np.max(full_data)]]*np.size(inp, 1)\n",
    "  neurons = np.size(tar, 1)\n",
    "\n",
    "  net = nl.net.newff(minmax,[10,neurons])\n",
    "  error = net.train(inp, tar, epochs=100, show=10, goal=0.02)\n",
    "  return net\n",
    "\n",
    "def learnFromFile(filepath):\n",
    "  df = pd.read_excel(filepath, skiprows = 0)\n",
    "  df.columns = df.columns.astype(str)# make all columns as str\n",
    "\n",
    "  # get years\n",
    "  columns = df.columns.to_numpy().astype(str)\n",
    "  years = np.unique([int(columns[i][0:4]) for i in range(1, np.size(columns))])\n",
    "  print('learning...')\n",
    "  N = []\n",
    "  R = []\n",
    "  previous_grades = []\n",
    "  for i in range(np.size(years)-1):\n",
    "    current_year = years[i]\n",
    "    next_year = years[i+1]\n",
    "    current_year_grades ,_ = getYear(df, current_year)\n",
    "    next_year_grades ,_ = getYear(df, next_year)\n",
    "    if i >0:\n",
    "      previous_grades = np.concatenate((previous_grades, current_year_grades), 1)\n",
    "    else:\n",
    "      previous_grades = current_year_grades.copy()\n",
    "    # regression coefficients\n",
    "    r = regressGrades(previous_grades, next_year_grades)\n",
    "    nan_cond = np.where(np.isnan(r))\n",
    "    r[nan_cond] = 0\n",
    "    print(np.shape(previous_grades), np.shape(current_year_grades))\n",
    "    # Multi-layer perceptron\n",
    "    shift = 4\n",
    "    inp = previous_grades-shift\n",
    "    tar = next_year_grades-shift\n",
    "    net = miniNet(inp, tar)\n",
    "    #print(current_year_grades, next_year_grades, r, current_year)\n",
    "    R.append(r)\n",
    "    N.append(net)\n",
    "  return R, N\n",
    "\n",
    "def predictByFile(filepath, prediction_rates, neural_networks):\n",
    "  st_df = pd.read_excel(filepath, skiprows = 0)# read student's data\n",
    "  st_df.drop(st_df.columns[[0]], axis=1, inplace=True)\n",
    "  #print(st_df)\n",
    "  st_df.columns = st_df.columns.astype(str)# make all columns as str\n",
    "\n",
    "  # get years\n",
    "  columns = st_df.columns.to_numpy().astype(str)\n",
    "  years = np.unique([int(columns[i][0:4]) for i in range(np.size(columns))])\n",
    "  print(years)\n",
    "  years = np.delete(years, -1) # we don't need the last year\n",
    " \n",
    "\n",
    "  overal_grades = [];\n",
    "  overal_columns = [];\n",
    "  for i in range(np.size(years)):\n",
    "    year = years[i]\n",
    "    R = prediction_rates[i]# current 'regression coefficients'\n",
    "    net = neural_networks[i]# current neural network\n",
    "\n",
    "    # get grades  \n",
    "    spike_cols = [col for col in st_df.columns if str(year) in col]\n",
    "    #print(spike_cols)\n",
    "    #print(st_df[spike_cols].to_numpy()[0], year)\n",
    "    data_out = st_df[spike_cols].to_numpy()[0, :].astype(float)    \n",
    "    current_year_grades = data_out.copy()\n",
    "\n",
    "    # names of the subject\n",
    "    #columns = st_df[spike_cols].to_numpy()[0].astype(str)\n",
    "    #overal_columns = np.concatenate((overal_columns, columns), 0)\n",
    "    \n",
    "    if i > 0:\n",
    "      # remove nan values by previously predicted grades\n",
    "      nan_cond = np.where(np.isnan(current_year_grades))\n",
    "      current_year_grades[nan_cond] = predicted_grades[nan_cond]  \n",
    "      \n",
    "    # concatenate all grades for the next prediction\n",
    "    overal_grades = np.concatenate((overal_grades, current_year_grades))\n",
    "\n",
    "    # predict the next year\n",
    "    predicted_grades = predictGrades(overal_grades, R) \n",
    "    #print(predicted_grades, ' - predicted') \n",
    "    shift = 4\n",
    "    x = overal_grades-shift\n",
    "    net_output = (net.sim([x.tolist()])+shift).squeeze()\n",
    "    \n",
    "    final_grades = np.concatenate((overal_grades, net_output))\n",
    "    final_columns = st_df.to_numpy()[0].astype(str)\n",
    "  #print(overal_columns, final_grades)\n",
    "\n",
    "  st_df.loc['predicted'] = final_grades\n",
    "  \n",
    "  return st_df#final_grades, final_columns\n",
    "\n",
    "def excel_to_blobmedia(filepath):\n",
    "    df = pd.read_excel(filepath, skiprows = 0)# read student's data\n",
    "    content = io.BytesIO()\n",
    "    df.to_excel(content, index=False)\n",
    "    content.seek(0, 0)\n",
    "\n",
    "    head, tail = os.path.split(filepath)\n",
    "\n",
    "    return anvil.BlobMedia(content=content.read(), content_type=\"application/vnd.ms-excel\", name=tail)\n",
    "\n",
    "\n",
    "\n",
    "current_folder = os.getcwd()\n",
    "dir = os.path.join(current_folder, 'StudentNeuralNetwork')\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "\n",
    "student_data_file = dir + '\\\\student_data_in_v2.xlsx'\n",
    "predicted_data_file = dir + '\\\\student_data_out.xlsx'\n",
    "@anvil.server.callable\n",
    "# https://anvil.works/forum/t/upload-file-to-uplink-local-storage-using-file-loader/3693\n",
    "def saveTable(file):\n",
    "  with open(student_data_file, 'wb') as f:\n",
    "    f.write(file.get_bytes())\n",
    "\n",
    "@anvil.server.callable\n",
    "def saveDataset(file):\n",
    "  filepath = dir + '\\\\dataset.xlsx'\n",
    "  with open(filepath, 'wb') as f:\n",
    "    f.write(file.get_bytes())\n",
    "  R, N = learnFromFile(filepath)\n",
    "  pickle.dump( R, open( dir + \"\\\\R.p\", \"wb\" ) )\n",
    "  pickle.dump( N, open( dir + \"\\\\N.p\", \"wb\" ) )\n",
    "  return 'Dataset is loaded'\n",
    "\n",
    "@anvil.server.callable\n",
    "def callThePrediction():\n",
    "  R = pickle.load( open( dir + \"\\\\R.p\", \"rb\" ) )\n",
    "  N = pickle.load( open( dir + \"\\\\N.p\", \"rb\" ) )\n",
    "  df = predictByFile(student_data_file, R, N)\n",
    "  df.to_excel(predicted_data_file, index=False)\n",
    "  time.sleep(1)\n",
    "  # https://anvil.works/forum/t/download-excel-file/7464/4\n",
    "  media_out = excel_to_blobmedia(predicted_data_file)\n",
    "  time.sleep(1)\n",
    "  return media_out\n",
    "\n",
    "webbrowser.open(\"https://OHI7U7ZW5FYT3CYA.anvil.app/EDVDCBWVPGRCDNKKX6IBF22R\", new=1)\n",
    "anvil.server.connect('RMSJ4GHU4YIGH3T5VHOWSHL2-OHI7U7ZW5FYT3CYA')\n",
    "anvil.server.wait_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-feeling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
